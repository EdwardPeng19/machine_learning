{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:27:15.111377Z",
     "start_time": "2018-09-21T12:27:13.472467Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:33:42.979248Z",
     "start_time": "2018-09-21T12:27:19.129009Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '../input/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../input/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    \"../input/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T00:45:17.011388Z",
     "start_time": "2018-09-24T00:45:16.972793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.000000     ...        1.098612   \n",
       "          99197       0.000000    0.693147     ...        0.000000   \n",
       "          103520      0.693147    0.693147     ...        0.000000   \n",
       "          103665      0.000000    2.079442     ...        0.693147   \n",
       "          105574      1.386294    2.302585     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612    0.000000    0.000000    0.693147   \n",
       "          99197       1.098612    0.000000    1.098612    0.000000   \n",
       "          103520      0.000000    1.386294    0.000000    1.386294   \n",
       "          103665      1.098612    0.000000    2.079442    2.302585   \n",
       "          105574      1.791759    2.079442    1.945910    2.397895   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      1.098612    0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:37:44.816363Z",
     "start_time": "2018-09-21T12:36:32.239267Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:37:44.874151Z",
     "start_time": "2018-09-21T12:37:44.818877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.000000     ...        1.098612   \n",
       "          99197       0.000000    0.693147     ...        0.000000   \n",
       "          103520      0.693147    0.693147     ...        0.000000   \n",
       "          103665      0.000000    2.079442     ...        0.693147   \n",
       "          105574      1.386294    2.302585     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612    0.000000    0.000000    0.693147   \n",
       "          99197       1.098612    0.000000    1.098612    0.000000   \n",
       "          103520      0.000000    1.386294    0.000000    1.386294   \n",
       "          103665      1.098612    0.000000    2.079442    2.302585   \n",
       "          105574      1.791759    2.079442    1.945910    2.397895   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      1.098612    0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:37:44.888357Z",
     "start_time": "2018-09-21T12:37:44.876066Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:37:44.932850Z",
     "start_time": "2018-09-21T12:37:44.891346Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.032042Z",
     "start_time": "2018-09-21T12:37:44.936843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "X_l, y_l = [], []\n",
    "for i in range(6):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.038105Z",
     "start_time": "2018-09-21T12:38:01.033834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores_items = pd.DataFrame(index=df_2017.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.067991Z",
     "start_time": "2018-09-21T12:38:01.041442Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = df_test[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.077908Z",
     "start_time": "2018-09-21T12:38:01.070093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = items.reindex( stores_items.index.get_level_values(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.088553Z",
     "start_time": "2018-09-21T12:38:01.080595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005090, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.374071Z",
     "start_time": "2018-09-21T12:38:01.092095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/algor/zhoubin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/algor/zhoubin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/opt/algor/zhoubin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "X_val = X_val.as_matrix()\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T12:38:01.381692Z",
     "start_time": "2018-09-21T12:38:01.375907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005090, 1, 40)\n",
      "(167515, 1, 40)\n",
      "(167515, 1, 40)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch构建lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T23:55:05.072409Z",
     "start_time": "2018-09-21T23:55:05.066962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 5               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 512\n",
    "TIME_STEP = 1         # rnn time step / image height\n",
    "INPUT_SIZE = 40         # rnn input size / image width\n",
    "LR = 0.001               # learning rate\n",
    "\n",
    "num_workers = 4\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T23:55:07.539617Z",
     "start_time": "2018-09-21T23:55:07.526201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=32,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "        \n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T23:55:08.641539Z",
     "start_time": "2018-09-21T23:55:08.637204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(40, 32, batch_first=True)\n",
      "  (out): Sequential(\n",
      "    (0): Dropout(p=0.1)\n",
      "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T23:55:11.128363Z",
     "start_time": "2018-09-21T23:55:11.106118Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pytorch自定义损失函数 Normalized Weighted Root Mean Squared Logarithmic Error(NWRMSLE)\n",
    "# 这里y真实值需要提前进行log1p的操作\n",
    "from torch.functional import F\n",
    "\n",
    "class my_rmseloss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(my_rmseloss, self).__init__()\n",
    "        return \n",
    "    \n",
    "    def forward(self, input, target, sample_weights=None):\n",
    "        self._assert_no_grad(target)\n",
    "        f_revis = lambda a, b, w: ((a - b) ** 2) * w # 重写\n",
    "        return self._pointwise_loss(f_revis, torch._C._nn.mse_loss,\n",
    "                           input, target, sample_weights)\n",
    "    \n",
    "    # 重写_pointwise_loss\n",
    "    def _pointwise_loss(self, lambd, lambd_optimized, input, target, sample_weights):\n",
    "        if target.requires_grad:\n",
    "            d = lambd(input, target, sample_weights)\n",
    "#             return torch.sqrt(torch.div(torch.sum(d), torch.sum(sample_weights)))\n",
    "            return torch.div(torch.sum(d), torch.sum(sample_weights))\n",
    "        else:\n",
    "            if sample_weights is not None:\n",
    "                unrooted_res = torch.div(torch.sum(torch.mul(lambd_optimized(input, target),sample_weights)),torch.sum(sample_weights))\n",
    "#                 return torch.sqrt(unrooted_res)\n",
    "                return unrooted_res\n",
    "            return lambd_optimized(input, target, 1)\n",
    "    \n",
    "    def _assert_no_grad(self, tensor):\n",
    "        assert not tensor.requires_grad, \\\n",
    "            \"nn criterions don't compute the gradient w.r.t. targets - please \" \\\n",
    "            \"mark these tensors as not requiring gradients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-21T23:55:15.577260Z",
     "start_time": "2018-09-21T23:55:15.573948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "# loss_func = nn.MSELoss()                       # the target label is not one-hotted\n",
    "loss_func = my_rmseloss() # self define loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理成tensor，并跑lstm模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-21T23:55:26.466Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2754 | val loss: 0.3264\n",
      "Epoch:  1 | train loss: 0.3201 | val loss: 0.3200\n",
      "Epoch:  2 | train loss: 0.3005 | val loss: 0.3105\n"
     ]
    }
   ],
   "source": [
    "# numpy数据处理成tensor\n",
    "\n",
    "trainX_tensor = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "valX_tensor = torch.from_numpy(X_val).type(torch.FloatTensor)\n",
    "testX_tesnsor = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "\n",
    "# sample weights\n",
    "sample_weights=np.array(pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1)\n",
    "sample_weights_train_tensor = torch.from_numpy(sample_weights).type(torch.FloatTensor)\n",
    "sample_weights_val_tensor = torch.from_numpy(np.array(items[\"perishable\"] * 0.25 + 1)).type(torch.FloatTensor)\n",
    "\n",
    "# 总共要预测16列\n",
    "for i in tqdm_notebook(range(16)):\n",
    "    \n",
    "    best_model = None\n",
    "    val_loss_prev = 9999\n",
    "\n",
    "    # 预测16个日期的销量，每个i是一个日期\n",
    "    trainY_tensor = torch.from_numpy(y_train[:,i]).type(torch.FloatTensor)\n",
    "    valY_tensor = torch.from_numpy(y_val[:,i]).type(torch.FloatTensor)\n",
    "\n",
    "    # 组装成dataset，到时候放入dataloader(放入dataloader是为了进行批训练)\n",
    "    torch_dataset = Data.TensorDataset(trainX_tensor, trainY_tensor, sample_weights_train_tensor)\n",
    "    train_loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      # torch TensorDataset format\n",
    "        batch_size=BATCH_SIZE,      # mini batch size\n",
    "        shuffle=True,               # random shuffle for training\n",
    "        num_workers=num_workers,              # subprocesses for loading data\n",
    "    )\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (b_x, b_y, sample_w) in enumerate(train_loader):        # gives batch data\n",
    "\n",
    "            output = rnn(b_x).squeeze()                     # rnn output\n",
    "            loss = loss_func(output, b_y, sample_weights=sample_w)         # calc NWRMSE loss\n",
    "            optimizer.zero_grad()                           # clear gradients for this training step\n",
    "            loss.backward()                                 # backpropagation, compute gradients\n",
    "            optimizer.step()                                # apply gradients\n",
    "\n",
    "        val_output = rnn(valX_tensor).squeeze()                   # (samples, time_step, input_size)\n",
    "        # 然后比较一下验证集的输出和真实值算mse\n",
    "        val_loss = loss_func(val_output, valY_tensor, sample_weights=sample_weights_val_tensor)\n",
    "        val_loss = float(val_loss.detach().data.numpy())\n",
    "        if  val_loss < val_loss_prev:\n",
    "            best_model = copy.deepcopy(rnn)\n",
    "            val_loss_prev = val_loss\n",
    "        print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| val loss: %.4f' % val_loss)\n",
    "    val_pred.append(best_model(valX_tensor).squeeze().data.numpy())\n",
    "    test_pred.append(best_model(testX_tesnsor).squeeze().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-21T23:55:31.049Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.array(test_pred).squeeze().transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=stores_items.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "submission = test_ids.join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('../output/lstm_v5.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据封装 (不用管)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX_tensor = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "trainY_tensor = torch.from_numpy(y_train[:,0]).type(torch.FloatTensor)\n",
    "valX_tensor = torch.from_numpy(X_val).type(torch.FloatTensor)\n",
    "valY_tensor = torch.from_numpy(y_val[:,0]).type(torch.FloatTensor)\n",
    "testX_tesnsor = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "\n",
    "sample_weights=np.array(pd.concat([items[\"perishable\"]] * 6) * 0.25 + 1)\n",
    "sample_weights_train_tensor = torch.from_numpy(sample_weights).type(torch.FloatTensor)\n",
    "sample_weights_val_tensor = torch.from_numpy(np.array(items[\"perishable\"] * 0.25 + 1)).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 组装成dataset，到时候放入dataloader(放入dataloader是为了进行批训练)\n",
    "torch_dataset = Data.TensorDataset(trainX_tensor, trainY_tensor, sample_weights_train_tensor)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=num_workers,              # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}