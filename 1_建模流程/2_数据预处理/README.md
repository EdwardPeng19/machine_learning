<h1 align = "left">:alien: 数据预处理 :alien:</h1>

---

## 数据清洗

 - **处理缺失值**<br>
常见的缺失值补全方法：均值，中值，众数插补、建模预测、高维映射<br>
（1）连续值<br>
特征值为连续值：按不同的分布类型对缺失值进行补全：偏正态分布，使用均值代替，可以保持数据的均值；<br>
偏长尾分布，使用中值代替，避免受 outlier 的影响<br>
（2）离散值<br>
使用众数代替，或者直接编码为'其他'<br>
（3）建模预测<br>
将缺失的属性作为预测目标来预测，将数据集按照是否含有特定属性的缺失值分为两类，利用现有的机器学习算法对待预测数据集的缺失值进行预测<br>
该方法的根本的缺陷是如果其他属性和缺失属性无关，则预测的结果毫无意义，但是若预测结果相当准确，则说明这个缺失属性是没必要纳入数据集中的，一般的情况是介于两者之间<br>
（4）高维映射star<br>
将属性映射到高维空间，采用独热码编码（one-hot）技术。将包含K个离散取值范围的属性值扩展为K+1个属性值，若该属性值缺失，则扩展后的第K+1个属性值置为1<br>
这种做法是最精确的做法，保留了所有的信息，也未添加任何额外信息，若预处理时把所有的变量都这样处理，会大大增加数据的维度。这样做的好处是完整保留了原始数据的全部信息、不用考虑缺失值；缺点是计算量大大提升，且只有在样本量非常大的时候效果才好<br>

 - **数据平滑**<br>
 比如分箱，贝叶斯平滑
 
 - **文本数据清洗**<br>
在比赛当中，如果数据包含文本，往往需要进行大量的数据清洗工作。如去除HTML 标签，分词，拼写纠正, 同义词替换，去除停词，抽词干，数字和单位格式统一等

## 数据集成

(1) 将多个数据源中的数据结合起来并统一存储，建立数据仓库的过程实际上就是数据集成，具体来讲就是将分散在不同来源的数据有机地整合到一起的一步，例如宽表整合<br>
(2) 提供的数据散落在多个文件，需要根据相应的键值进行数据的拼接

## 数据变换(又可属于特征工程)

 - **特征变换**<br>
主要针对一些长尾分布的特征，需要进行幂变换或者对数变换，使得模型（LR或者DNN）能更好的优化。<br>
需要注意的是，Random Forest 和 GBDT 等模型对单调的函数变换不敏感。其原因在于树模型在求解分裂点的时候，只考虑排序分位点
 
 - **特征编码**<br>
比如二值化、多值化（分箱）、one-hot等<br>
 
 - **数据标准化、正则化**<br>
（1）min-max标准化<br>
对于每个属性，设minA和maxA分别为属性A的最小值和最大值，将A的一个原始值x通过min-max标准化映射成在区间[0,1]中的值x'，其公式为：新数据 =（原数据 - 最小值）/（最大值 - 最小值）<br>
（2）z-score标准化<br>
基于原始数据的均值（mean）和标准差（standarddeviation）进行数据的标准化。将A的原始值x使用z-score标准化到x'。z-score标准化方法适用于属性A的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。新数据 =（原数据- 均值）/ 标准差 <br>
（3）数据正则化<br>
每个属性值除以其Lp范数，将样本缩放到单位范数(一般不用在这里)

## 数据归约

- **维规约**（检测并删除不相关、弱相关或冗余的属性或维）<br>
- **数据压缩**（小波或傅立叶变换以及主成份分析）

